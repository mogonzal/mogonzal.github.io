(self.webpackChunkmogonzal_website=self.webpackChunkmogonzal_website||[]).push([[145],{5736:function(e,t,n){"use strict";n.r(t),n.d(t,{Head:function(){return h},default:function(){return m}});var o=n(1151),s=n(7294),r=n(3779),a=n(7947);function i(e){const t=Object.assign({p:"p",strong:"strong",em:"em"},(0,o.ah)(),e.components);return s.createElement(s.Fragment,null,s.createElement("p",{className:"font-bold text-lg sm:text-3xl"}," tl;dr "),"\n",s.createElement(t.p,null,"I designed an efficient algorithm for time-constrained seed selection in competing cascade graphs."),"\n",s.createElement("br"),"\n",s.createElement("p",{className:"font-bold text-lg sm:text-3xl"}," Overview "),"\n",s.createElement(t.p,null,"As part of another yearly Caltech tradition, students in CS 144 are exposed to an emerging hot topic in\nnetworks—competing cascades. A competing cascade on graph ",s.createElement(a.Z,{displayMode:"inline",formula:"G = (V,E)"})," is defined as follows:"),"\n",s.createElement("br"),"\n",s.createElement("ul",{className:"list-disc list-inside"},s.createElement("li",null,s.createElement(t.p,null,s.createElement(t.strong,null,"Initialization"),": each node in ",s.createElement(a.Z,{displayMode:"inline",formula:"G"})," begins uncolored.")),s.createElement("li",null,s.createElement(t.p,null,s.createElement(t.strong,null,"Seeding"),": each team selects ",s.createElement(a.Z,{displayMode:"inline",formula:"k"})," seed nodes to start with their respective color. If two teams attempt to seed the\nsame node, it begins blank. With the colored seeds set, we now begin rounds of spreading.")),s.createElement("li",null,s.createElement(t.p,null,s.createElement(t.strong,null,"During each round"),": each node ",s.createElement(a.Z,{displayMode:"inline",formula:"n \\in G"})," looks at its non-blank neighbors and totals the number of each color. If\nany color's total obtains a strict majority (over half) of the total sum, ",s.createElement(a.Z,{displayMode:"inline",formula:"n"})," takes on that color at the end\nof the round. Note that if ",s.createElement(a.Z,{displayMode:"inline",formula:"n"}),' already has a color, it also "votes" for its own color with weight 1.5.')),s.createElement("li",null,s.createElement(t.p,null,s.createElement(t.strong,null,"Termination"),": rounds continue until convergence, meaning no nodes change color during a round. Note that there is a small chance\ncolors oscillate infinitely; if this occurs then we choose a random number of rounds ",s.createElement(a.Z,{displayMode:"inline",formula:"\\in [100, 200]"})," to stop.")),s.createElement("li",null,s.createElement(t.p,null,s.createElement(t.strong,null,"Scoring"),": after convergence or a manual stop, the team with the most nodes of their respective color wins. If\nboth teams happened to select the exact same ",s.createElement(a.Z,{displayMode:"inline",formula:"k"})," seed nodes, both are awarded a loss."))),"\n",s.createElement("br"),"\n",s.createElement(t.p,null,"Note that the definition above admits cascades with an unlimited number of teams, but here we focus mostly on two-team\ncascades. Using the above cascade mechanics, the Pandemaniac challenge is run according to the following procedure:"),"\n",s.createElement("br"),"\n",s.createElement("ul",{className:"list-disc list-inside"},s.createElement("li",null,s.createElement(t.p,null,"Teams are given access to graphs on the course website, where each file stores the graph in adjacency list format as\nwell as the number of seed nodes ",s.createElement(t.em,null,"k")," to select.")),s.createElement("li",null,s.createElement(t.p,null,"From the moment a team downloads a graph file, they have a maximum of 5 minutes to submit a text file containing\ntheir desired seed nodes.")),s.createElement("li",null,s.createElement(t.p,null,"Each day of the challenge, a few graphs are released and each team's seeds are pitted round-robin style against all\nother teams. Team with the best overall records would then face off elimination style until a winner was crowned."))),"\n",s.createElement("br"),"\n",s.createElement(t.p,null,"Pandemaniac is clearly a complicated game and the development of a winning strategy will involve some combination of\ngraph theory as well as game theory. Do we opt to choose simply the highest-degree nodes in the graph, or perhaps use\nsome other measure of centrality? Do we prioritize nodes that the other team is unlikely to seed in order to avoid\npicking the same ones? The answers to these questions will become apparent as we explore tools and strategies below."),"\n",s.createElement("br"),"\n",s.createElement("p",{className:"font-bold text-lg sm:text-3xl"}," Tools "),"\n",s.createElement(t.p,null,"The simulation code provided with the sample project files was adequate for simple testing, but we knew from the start\nthat our strategy would likely involve many successive simulations. Thus, we sought to improve the simulation code to\nbe more efficient. For reference, the original simulation roughly followed the pseucode below:"),"\n",s.createElement("div",{className:"flex justify-center"},s.createElement("div",{className:"p-4 w-full sm:w-fit"},s.createElement(r.p,{language:"python"},"def original_sim(G, seeds1, seeds2):\n  # Initialize the graph with the given seeds.\n  for node in seeds1:\n    G[node].color = color1\n\n  for node in seeds2:\n    if G[node].color == blank:\n      G[node].color = color2\n    else:\n      G[node].color = blank\n\n  # Run until convergence or manual stop.\n  max_iter = random_int(100, 200)\n  iter = 0\n  new_G = None\n\n  while G != new_G and iter < max_iter:\n    new_G = G.copy()\n    for node in G:\n      totals = [0, 0]\n      for neighbor in node.neighbors:\n        if neighbor.color != blank:\n          totals[neighbor.color] += 1\n        \n      if node.color != blank:\n        totals[node.color] += 1.5\n\n      if totals[color1] > node.nonblank_neighbors:\n        new_G[node].color = color1\n      elif totals[color2] > node.nonblank_neighbors:\n        new_G[node].color = color2\n\n    G = new_G\n    iter += 1\n\n  # Count up colors.\n  totals = [0, 0]\n  for node in G:\n    if node.color != blank:\n      totals[node] += 1\n\n  return totals\n"))),"\n",s.createElement(t.p,null,"The first improvement simply optimized the original code to avoid unnecessary neighbor checks. For the original\nsimulator, each round requires looking through every node in the graph as well as every neighbor at a given node. This\nincludes nodes that have no colored neighbors and have no reason to be checked in the first place. The improvement we\nmade was to look only at nodes that we'd previously marked as “needing updating.” When a node updates its color, it\nupdates the votes for its color for each of its neighbors and marks the neighbor as needing updating. Thus, we only look\nthrough the necessary nodes at each iteration. In testing, this produced about a 30% time save and allowed us to start\npursuing brute force strategies with higher success."),"\n",s.createElement("div",{className:"flex justify-center"},s.createElement("div",{className:"p-4 w-full sm:w-fit"},s.createElement(r.p,{language:"python"},"def better_sim(G, seeds1, seeds2):\n  # Initialize the graph with the given seeds.\n  for node in seeds1:\n    G[node].color = color1\n\n  for node in seeds2:\n    if G[node].color == blank:\n      G[node].color = color2\n    else:\n      G[node].color = blank\n\n  # Figure out which nodes we actually need to check (neighbors of colored nodes).\n  to_check = set()\n\n  for node in set_diff(seeds1, seeds2):\n    for neighbor in node.neighbors:\n      to_check.add(neighbor)\n\n  # Run until convergence or manual stop.\n  max_iter = random_int(100, 200)\n  iters = 0\n\n  while iters < max_iter:\n    to_update = set()\n\n    for node in to_check:\n      for color in colors:\n        if node.color == blank and node.counts[color] > node.nonblank_neighbors:\n          for neighbor in node.neighbors:\n            neighbor.new_nonblank_neighbors += 1\n            neighbor.new_counts[color] += 1\n            to_update.add(neighbor)\n            to_check.add(neighbor)\n          node.color = color\n        elif node.color != color and node.counts[color] > node.nonblank_neighbors + 1.5:\n          for neighbor in node.neighbors:\n            neighbor.new_counts[node.color] -= 1\n            neighbor.new_counts[color] += 1\n            to_update.add(neighbor)\n            to_check.add(neighbor)\n          node.color = color\n\n    if to_update.is_empty():\n      break\n\n    for node in to_update:\n      node.nonblank_neighbors = node.new_nonblank_neighbors\n      node.counts = node.new_counts\n\n    iters += 1\n\n  # Count up colors.\n  totals = [0, 0]\n  for node in G:\n    if node.color != blank:\n      totals[node] += 1\n\n  return totals, iters\n"))),"\n",s.createElement(t.p,null,"The second improvement was essentially a complete redesign of the simulation that foregoes traversing a graph\naltogether. Instead, it takes advantage of sparese matrix multiplication, which is much quicker. For a game with two\ncolors, we can accomplish this by creating vector ",s.createElement(a.Z,{displayMode:"inline",formula:"b"})," and matrix ",s.createElement(a.Z,{displayMode:"inline",formula:"A"})," with the following setup:"),"\n",s.createElement(a.Z,{displayMode:"block",formula:"\nb_i =\n\\begin{cases}\n1, & \\text{if node } i \\text{ is color 1} \\\\\n-1, & \\text{if node } i \\text{ is color 2}\n\\end{cases},~~~~\nA_{ij} =\n\\begin{cases}\n1, & \\text{if node } i \\text{ shares an edge with node } j \\\\\n1.5, & \\text{if } i = j \\\\\n0, & \\text{otherwise}\n\\end{cases}\n"}),"\n",s.createElement(t.p,null,"Note that ",s.createElement(a.Z,{displayMode:"inline",formula:"A"})," is exactly the adjacency matrix with a superimposed diagonal of value 1.5. What the above setup\naccomplishes is the ability to represent a given round of the cascade as ",s.createElement(a.Z,{displayMode:"inline",formula:"\\text{sign}(bA)"}),". If this is unclear, perhaps take some time to convince yourself that this is true. But we\nnow had a way to rapidly simulate cascade games using just a few lines of linear algebra."),"\n",s.createElement("div",{className:"flex justify-center"},s.createElement("div",{className:"p-4 w-full sm:w-fit"},s.createElement(r.p,{language:"python"},"import numpy as np\n\ndef best_sim(G, n1, n2):  \n  if seed1 == seed2:\n    return 0.0, 0.0\n\n  # Construct initial seeding for each color.\n  n = A.shape[G.order()]\n  A = G.adjacency_matrix() + np.identity(n)\n  curr = np.zeros(n).reshape((-1,1))\n  curr[list(seed1)] += 1\n  curr[list(seed2)] -= 1\n\n  # Simulate until convergence or max iterations reached\n  max_iter = max_rounds = np.random.randint(100, 200)\n  iter = 0\n  prev = None\n\n  while (prev != curr).any() and iter < max_iter:\n    prev = curr\n    curr = np.sign(A @ prev)\n    iter += 1\n\n  curr = np.array(curr).flatten()\n  counts = collections.Counter(curr)\n  return counts[1], counts[-1]\n"))),"\n",s.createElement(t.p,null,"After implementing most of our strategies using Python and heavily leveraging NumPy, we decided to try making it faster.\nThe first thing we tried was PyTorch, which is a GPU-enabled ML library. The syntax and functionality is very similar to\nNumPy. After implementing the changes, at least on our MacBooks (which was primarily what we had access to), there was a\nmarginal improvement over NumPy. We then tried CuPy, which is a numpy version that leverages CUDA for improvements, but\nour windows desktops were not able to run CuPy due to some CUDA issues, and it was not supported on Apple silicon for\nobvious reasons. Afterwards, we stumbled across a special version of NumPy that is optimized for Apple silicon, and\nimmediately saw an average of over a 5x increase in processing speed over base NumPy, and a 2x improvement over the\nPyTorch implementation. This is ultimately what we went for. Using these improvements, we were able to increase\nprocessing for our final strategy from ~100-150k iterations to over 1 million."),"\n",s.createElement("br"),"\n",s.createElement("p",{className:"font-bold text-lg sm:text-3xl"}," Potential Strategies "),"\n",s.createElement(t.p,null,s.createElement(t.strong,null,"Weighted"),": the first potential strategy was created by doing some testing with the provided simulation. We saw that\nthe winning strategies usually had mostly high-centrality nodes, so we decided to develop around it. In graph analysis,\nthe three main centrality measurements are ",s.createElement(t.em,null,"degree"),", ",s.createElement(t.em,null,"betweenness"),", and ",s.createElement(t.em,null,"closeness")," centrality and are defined for node\n",s.createElement(a.Z,{displayMode:"inline",formula:"v"})," as follows:"),"\n",s.createElement(a.Z,{displayMode:"block",formula:"\n\\begin{aligned}\n\\text{Degree Centrality: } & C_D(v) = \\frac{deg(v)}{n-1} \\\\\n\\text{Betweenness Centrality: } & C_B(v) = \\sum_{s\\neq v\\neq t}\\frac{\\sigma_{s,t}(v)}{\\sigma_{s,t}} \\\\\n\\text{Closeness Centrality: } & C_C(v) = \\frac{1}{\\sum_{u\\in V} d(v,u)}\n\\end{aligned}\n"}),"\n",s.createElement(t.p,null,"Nodes of high centrality are very useful because they are more likely to spread their color faster because of how\nconnected they are to the rest of the graph. For this strategy we took each of the above centralities and applyied a\nweight to each, choosing the nodes with the highest rank after weighting. We then iterated over all discrete\ncombinations of centrality weights, and pitted each combination against each other. Ultimately, we took the strategy\nthat won the most from this."),"\n",s.createElement("br"),"\n",s.createElement(t.p,null,s.createElement(t.strong,null,"Genetic"),": Given that Pandemaniac is a kind of game, we took inspiration from genetic algorithms developed to find how\nto play video games in an unsupervised way. To do this, we started with a population of size ",s.createElement(a.Z,{displayMode:"inline",formula:"n"})," seedings that contained random strategies made by randomly selecting nodes from the graph. We then\ncalculated the “fitness” of each strategy, which basically consisted of pitting each strategy in the population against\neach other. The resulting fitness is a measure of how many games that seeding won. We then take the top 2 strategies as\n“parents” to generate “offspring” by generating ",s.createElement(a.Z,{displayMode:"inline",formula:"n-2"})," new seedings by randomly\nchoosing ",s.createElement(a.Z,{displayMode:"inline",formula:"k"})," seeds from the set of seeds from both parents in the “crossover”\nstep. Finally, we had a “mutation” step, where a small subset of nodes from each offspring was randomly switched out\nwith some other node in the graph. This process repeated until the parent seeds did not change for 5 iterations, after\nwhich point we pit the final population against each other and took the winning-est seeding."),"\n",s.createElement("br"),"\n",s.createElement(t.p,null,s.createElement(t.strong,null,"Clustering"),": This strategy was less of an individual strategy and moreso a focusing of the above weighting strategy.\nThe goal was to reduce the problem scope, specifically by using k-means to find the largest cluster, and making use of\nthe weighted strategy to choose the best seed nodes within this cluster. The thinking was that if parts of the graph\nwere under contention, we’d be best off having a stronghold within the largest cluster. In testing this typically lost\nto a more generalized weighted strategy, or even simply the highest degree centrality nodes."),"\n",s.createElement("br"),"\n",s.createElement(t.p,null,"After extensive testing with the above 3 strategies, we pit the results together to get the overall winning-est\nstrategy. This usually ended up being from the first vein of strategies, specifically one in which degree centrality was\nweighted very highly. We used this empirical observation when developing our final strategy described below, which\n(surprisingly) has very little in common with the above three as it takes on more of a brute-force approach."),"\n",s.createElement("br"),"\n",s.createElement("p",{className:"font-bold text-lg sm:text-3xl"}," Developing a Final Strategy "),"\n",s.createElement(t.p,null,"Our final strategy has very little in common with the ones explored above and takes more of a brute-force approach. We\ndeveloped it in three different stages, which we describe below with some associated pseudocode. Note that our actual\nimplementations used Python's multiprocessing module to squeeze as much effort as possible out of the CPU within five\nminutes:"),"\n",s.createElement("br"),"\n",s.createElement(t.p,null,s.createElement(t.strong,null,"V0. Random brute force"),": This was our first foray into the black box we would eventually develop. The motivation\nbehind attempting this strategy to begin with is quite simple: despite our best efforts analytically, we could rarely\nfind seed nodes which outright beat degree centrality. Given how random it seemed, we thought it would be amusing to\ngenerate random seed nodes for 4 minutes and see if any beat degree centrality. To our surprise, this not only produced\nbetter results but also produced more results within the entire five-minute timespan. Thus, we elected to compete with\nthis for the first few days while we looked into optimizations."),"\n",s.createElement("div",{className:"flex justify-center"},s.createElement("div",{className:"p-4 w-full sm:w-fit"},s.createElement(r.p,{language:"python"},"from datetime import datetime\nimport random\n\ndef v0(G, k):\n  # Start with highest degree nodes.\n  t = datetime.now()\n  deg_seeds = sorted(G.nodes, key=G.degree, reverse=True)[:k]\n  scores = dict()\n\n  # Spend the entire time searching for seeds beating degree.\n  while (datetime.now() - t).total_seconds() < 240:\n    seeds = random.choice(G.nodes, k)\n\n    [n_us, n_deg] = original_sim(G, seeds, deg_seeds)\n\n    if n_us > n_deg:\n      scores[seeds] = n_us\n\n  # Pick set that performed best against degree (if found).\n  if len(scores) == 0:\n    return deg_seeds\n  return sorted(scores, key=scores.get)[-1]\n"))),"\n",s.createElement(t.p,null,"Given that our first improvement did not include any sort of analytical consideration and was based off of quick\nsimulations, we decided to double down on the strategy and looked into improvements that simulate even faster. So we\nimproved our sim to make use of matrix multiplication approach described in the tools above and changed our performance\nmetric to frontier expansion rate as opposed to nodes captured total. What this meant was that we measured how fast the\nseeds accumulated nodes by dividing the number of nodes accumulated over the number of iterations it took to converge.\nThis disincentivized non-convergent or slow-growing seeds. This was met with much better success than V0, but we still\nhad not cracked the top few teams."),"\n",s.createElement("div",{className:"flex justify-center"},s.createElement("div",{className:"p-4 w-full sm:w-fit"},s.createElement(r.p,{language:"python"},"from datetime import datetime\nimport random\n\ndef better_v0(G, k):\n  # Start with highest degree nodes.\n  t = datetime.now()\n  deg_seeds = sorted(G.nodes, key=G.degree, reverse=True)[:k]\n  scores = dict()\n\n  # Spend the entire time searching for seeds beating degree.\n  while (datetime.now() - t).total_seconds() < 240:\n    seeds = random.choice(G.nodes, k)\n\n    [n_us, n_deg], iters = better_sim(G, seeds, deg_seeds)\n\n    if n_us > n_deg:\n      scores[seeds] = n_us / iters\n\n  # Pick set that performed best against degree (if found).\n  if len(scores) == 0:\n    return deg_seeds\n  return sorted(scores, key=scores.get)[-1]\n"))),"\n",s.createElement(t.p,null,s.createElement(t.strong,null,"V1. Directed brute force"),": This is when the strategy really began to get smarter. Having invested significant time\ninto optimizing the simulation process, we instead shifted our focus on reducing the problem space itself. From\nempirical observation of results for the past few days, it appeared that most winning seeds consisted of some\ncombination of high-degree nodes, and a few (usually 1-3) slightly lower degree nodes. Knowing this, we developed a new\napproach that looked through seeds in a more efficient order (therefore increasing our odds of finding a good one within\nfive minutes). We accomplished this by first sorting nodes by degree centrality and then did the following at each\niteration: we chose a random number ",s.createElement(a.Z,{displayMode:"inline",formula:"m \\in [0, k/2]"}),". We then chose ",s.createElement(a.Z,{displayMode:"inline",formula:"k-m"})," seed nodes from the top ",s.createElement(a.Z,{displayMode:"inline",formula:"k"})," nodes as well as\n",s.createElement(a.Z,{displayMode:"inline",formula:"m"})," seed nodes from the remaining top 25% of nodes. This produced many more\nhigh-performing seeds, further strengthening our final result because we had enough seeds to do a final layer of testing\nbefore picking which one to submit. The final step consisted of filtering out the top 100 seeds from the above process,\npitting them all against each other, and submitting the one with the highest average win rate. As expected, this was met\nwith even more success during round robin matches, advancing us to the final round of the tournament!"),"\n",s.createElement("div",{className:"flex justify-center"},s.createElement("div",{className:"p-4 w-full sm:w-fit"},s.createElement(r.p,{language:"python"},"from datetime import datetime\nimport itertools\nimport random\n\ndef v1(G, k):\n  # Store highest degree nodes as well as top 25% of nodes by degree.\n  t = datetime.now()\n  deg_seeds = sorted(G.nodes, key=G.degree, reverse=True)[:k]\n  sample_nodes = sorted(G.nodes, key=G.degree, reverse=True)[k:G.degree // 4]\n\n  # Search for sets of seeds beating degree centrality.\n  tested = set()\n  scores = dict()\n\n  while (datetime.now() - t).total_seconds() < 240:\n    n_outside = random.randint(0, k//2)\n    nodes_outside = random.sample(sample_nodes, n_outside)\n    nodes_inside = random.sample(deg_seeds, k - n_outside)\n    seeds = union(nodes_outside, nodes_inside)\n\n    if seeds not in tested:\n      [score_us, score_deg] = best_sim(G, seeds, deg_seeds)\n      if n_us > n_deg:\n        scores[seeds] = score_us\n      tested.add(seeds)\n\n  if len(scores) == 0:\n    return deg_seeds\n\n  # Pit the top 100 combinations against each other.\n  top_seeds = sorted(scores, key=scores.get, reverse=True)[:100]\n  final_scores = {seed : 0 for seed in top_seeds}\n\n  for s1, s2 in itertools.combinations(top_seeds, 2):\n    s1_score, s2_score = best_sim(A, s1, s2)\n\n    if s1_score > s2_score:\n        final_scores[s1] += 1\n    if s1_score < s2_score:\n        final_scores[s2] += 1\n\n  return max(final_scores, key=final_scores.get)\n"))),"\n",s.createElement(t.p,null,s.createElement(t.strong,null,"V2. Greedy top-down search"),": As a final improvement, we decided to make the strategy get greedy in an effort to\nfurther improve the pool of high-performing seed nodes we iterate through. We begin with the highest degree nodes as our\nbaseline strategy and the current strategy. We then launch ",s.createElement(a.Z,{displayMode:"inline",formula:"k"})," (number of seeds)\nprocesses, where the ",s.createElement(a.Z,{displayMode:"inline",formula:"i"}),"th process is responsible for considering what would\nhappen if we replace the ith node of the current seed set with something new, confirming that seed hasn’t been tested\nyet, and testing it against the baseline. If it beats the baseline, we add the strategy to a winning dictionary that\nkeeps track of how much these strategies won by. After all processes finish iterating, we pool the winning dictionaries\ntogether, select the best performing seed from the last iteration as the new current strategy, and repeat. After 4\nminutes, we enact the same final step of testing as in V1 where the top 100 seedings from all iterations are put against\neach other and the set of seeds with the highest average win percentage is submitted."),"\n",s.createElement("div",{className:"flex justify-center"},s.createElement("div",{className:"p-4 w-full sm:w-fit"},s.createElement(r.p,{language:"python"},"from datetime import datetime\nimport random\n\ndef v2(G, k):\n  # Store highest degree nodes as well as top 25% of nodes by degree.\n  t = datetime.now()\n  deg_seeds = sorted(G.nodes, key=G.degree, reverse=True)[:k]\n  sample_nodes = sorted(G.nodes, key=G.degree, reverse=True)[k:G.degree // 4]\n\n  # Iterate through seeds by permuting individual nodes.\n  tested = set()\n  scores = dict()\n  curr = deg_seeds\n\n  while (datetime.now() - t).total_seconds() < 240:\n    tested_here = set()\n\n    for idx_to_remove in range(len(curr)):\n      for node in sample_nodes:\n        new_seed = curr\n        new_seed[idx_to-remove] = node\n\n        if new_seed not in tested:\n          [score_us, score_deg] = best_sim(G, seeds, deg_seeds)\n          if n_us > n_deg:\n            scores[seeds] = score_us\n          tested.add(seeds)\n          tested_here.add(seeds)\n\n    curr = max(tested_here, key=scores.get)\n  \n  # Pit the top 100 combinations against each other.\n  top_seeds = sorted(scores, key=scores.get, reverse=True)[:100]\n  final_scores = {seed : 0 for seed in top_seeds}\n\n  for s1, s2 in itertools.combinations(top_seeds, 2):\n    s1_score, s2_score = best_sim(A, s1, s2)\n\n    if s1_score > s2_score:\n        final_scores[s1] += 1\n    if s1_score < s2_score:\n        final_scores[s2] += 1\n\n  return max(final_scores, key=final_scores.get)\n"))),"\n",s.createElement("br"),"\n",s.createElement("p",{className:"font-bold text-lg sm:text-3xl"}," Results "),"\n",s.createElement(t.p,null,'Out of about 32 teams, we came in second place. As it turns out, the first-place team used pretty much the same strategy\nwe did, but with no final step. What this effectively accomplishes is that they found a pseudo-Nash equilibrium, a\nstrategy that was excellent at beating other "good" strategies but not necessarily average strategies. This makes a lot\nof sense in the context of previous rounds, where we mad a much better record against teams that employed surface-level\nstrategies like degree or betweenness centrality because we prioritized ',s.createElement(t.em,null,"average")," win rate instead of just wins against\ngood strategies."),"\n",s.createElement("br"),"\n",s.createElement(t.p,null,"Overall, I'm extremely pleased with how we did. I'm incredibly surprised with how effective a heavily-optimized brute\nforce approach worked, especially in a competition that has been a Caltech classic for many years. Perhaps this just\ngoes to show that sometimes simpler is better!"))}var l=function(e){void 0===e&&(e={});const{wrapper:t}=Object.assign({},(0,o.ah)(),e.components);return t?s.createElement(t,e,s.createElement(i,e)):i(e)},d=n(8678);const c=e=>{let{data:t,children:n}=e;return s.createElement(d.Z,{pageTitle:t.mdx.frontmatter.title},s.createElement("div",{className:"w-full sm:w-2/3"},n))},h=e=>{let{data:t}=e;return s.createElement("title",null,t.mdx.frontmatter.title)};function m(e){return s.createElement(c,e,s.createElement(l,e))}},7947:function(e,t,n){"use strict";var o=n(7294),s=n(7617);t.Z=e=>{let{displayMode:t,formula:n}=e;return"block"===t?o.createElement(s.BlockMath,null,n):o.createElement(s.InlineMath,null,n)}},7617:function(e,t,n){var o,s,r,a;a=function(e,t,n,o){"use strict";function s(e){return e&&e.__esModule?e:{default:e}}function r(e){if("function"!=typeof WeakMap)return null;var t=new WeakMap,n=new WeakMap;return(r=function(e){return e?n:t})(e)}function a(e,t){if(!t&&e&&e.__esModule)return e;if(null===e||"object"!=typeof e&&"function"!=typeof e)return{default:e};var n=r(t);if(n&&n.has(e))return n.get(e);var o={},s=Object.defineProperty&&Object.getOwnPropertyDescriptor;for(var a in e)if("default"!==a&&Object.prototype.hasOwnProperty.call(e,a)){var i=s?Object.getOwnPropertyDescriptor(e,a):null;i&&(i.get||i.set)?Object.defineProperty(o,a,i):o[a]=e[a]}return o.default=e,n&&n.set(e,o),o}Object.defineProperty(e,"__esModule",{value:!0}),function(e,t){for(var n in t)Object.defineProperty(e,n,{enumerable:!0,get:t[n]})}(e,{BlockMath:()=>h,InlineMath:()=>m}),t=a(t),n=s(n),o=s(o);const i=(e,{displayMode:s})=>{const r=({children:n,errorColor:r,math:a,renderError:i})=>{const l=null!=a?a:n,{html:d,error:c}=(0,t.useMemo)((()=>{try{return{html:o.default.renderToString(l,{displayMode:s,errorColor:r,throwOnError:!!i}),error:void 0}}catch(c){if(c instanceof o.default.ParseError||c instanceof TypeError)return{error:c};throw c}}),[l,r,i]);return c?i?i(c):t.default.createElement(e,{html:`${c.message}`}):t.default.createElement(e,{html:d})};return r.propTypes={children:n.default.string,errorColor:n.default.string,math:n.default.string,renderError:n.default.func},r},l={html:n.default.string.isRequired},d=({html:e})=>t.default.createElement("div",{"data-testid":"react-katex",dangerouslySetInnerHTML:{__html:e}});d.propTypes=l;const c=({html:e})=>t.default.createElement("span",{"data-testid":"react-katex",dangerouslySetInnerHTML:{__html:e}});c.propTypes=l;const h=i(d,{displayMode:!0}),m=i(c,{displayMode:!1})},"object"==typeof e.exports?a(t,n(7294),n(5697),n(527)):(s=[t,n(7294),n(5697),n(527)],void 0===(r="function"==typeof(o=a)?o.apply(t,s):o)||(e.exports=r))}}]);
//# sourceMappingURL=component---src-pages-projects-mdx-frontmatter-slug-js-content-file-path-users-michael-desktop-mogonzal-mogonzal-website-projects-cs-144-pandemaniac-cs-144-pandemaniac-mdx-8a6414a918d3243acc3d.js.map